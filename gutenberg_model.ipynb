{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mudit\\Anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\smart_open\\ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import gensim\n",
    "import re\n",
    "import sqlite3\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data from the sqlite database file into a Pandas dataframe\n",
    "cnx = sqlite3.connect('Data/gutenberg/gutenberg.sqlite3')\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT * FROM articles\", cnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop index column\n",
    "\n",
    "df.drop(columns=['id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['article'] = df['article'].map(lambda x: re.sub('\\r|\\n|\\'','',x))\n",
    "df['article'] = df['article'].map(lambda x: re.sub(r'--\\d\\d\\d-\\d\\d\\d-\\d\\d\\d\\d','',x))\n",
    "df['article'] = df['article'].map(lambda x: re.sub('\\s+',' ',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words_subset = set([x for x in stop_words if 3 <= len(x) <= 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(x): #x is the string input\n",
    "    word_set = x.split(' ')\n",
    "    for word in word_set:\n",
    "        if word in stop_words:\n",
    "            word_set.remove(word)\n",
    "    return ' '.join(word_set)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stopwords\n",
    "df['article'] = df['article'].map(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Twain, Mark'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['auth_name'].iloc[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply tf-idf vectorization on the article column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = str()\n",
    "for row in df['article'].iteritems():\n",
    "    corpus += row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus.split(' ')) #Tfidf Vectorizer accepts a list of strings as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.transform(list(df['article']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['auth_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying label binarizer to get one-hot encoding of the categorical text column 'auth_name'\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(df['auth_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform train-test split of the dataset:\n",
    "#Set the random_state attribute to some value so that train-test split returns the same training and testing subsets each time\n",
    "#Setting the stratify attribute ensures that there are instances of all classes(target features) in both train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.25,\n",
    "                                                   random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply a simple neural network on this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimension = X_train.shape[1] #This specifies the number of neurons in the input layer, in this case 444\n",
    "#Using Keras' sequential API\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(100, input_dim=input_dimension, activation='relu'))\n",
    "model.add(layers.Dense(42, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1575 samples, validate on 525 samples\n",
      "Epoch 1/100\n",
      "1575/1575 [==============================] - 34s 21ms/step - loss: 3.6358 - acc: 0.1276 - val_loss: 3.4635 - val_acc: 0.4267\n",
      "Epoch 2/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 2.8815 - acc: 0.8762 - val_loss: 2.7669 - val_acc: 0.7486\n",
      "Epoch 3/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 1.5198 - acc: 0.9917 - val_loss: 1.9428 - val_acc: 0.8895\n",
      "Epoch 4/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.4966 - acc: 0.9968 - val_loss: 1.4939 - val_acc: 0.9067\n",
      "Epoch 5/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.1765 - acc: 0.9975 - val_loss: 1.2867 - val_acc: 0.9048\n",
      "Epoch 6/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0887 - acc: 0.9975 - val_loss: 1.1597 - val_acc: 0.9181\n",
      "Epoch 7/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0565 - acc: 0.9975 - val_loss: 1.0738 - val_acc: 0.9200\n",
      "Epoch 8/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0410 - acc: 0.9975 - val_loss: 1.0091 - val_acc: 0.9371\n",
      "Epoch 9/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0322 - acc: 0.9975 - val_loss: 0.9614 - val_acc: 0.9333\n",
      "Epoch 10/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0267 - acc: 0.9975 - val_loss: 0.9204 - val_acc: 0.9352\n",
      "Epoch 11/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0229 - acc: 0.9975 - val_loss: 0.8858 - val_acc: 0.9371\n",
      "Epoch 12/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0201 - acc: 0.9975 - val_loss: 0.8573 - val_acc: 0.9371\n",
      "Epoch 13/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0179 - acc: 0.9975 - val_loss: 0.8320 - val_acc: 0.9371\n",
      "Epoch 14/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0163 - acc: 0.9975 - val_loss: 0.8104 - val_acc: 0.9352\n",
      "Epoch 15/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0149 - acc: 0.9975 - val_loss: 0.7890 - val_acc: 0.9352\n",
      "Epoch 16/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0137 - acc: 0.9975 - val_loss: 0.7717 - val_acc: 0.9333\n",
      "Epoch 17/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0128 - acc: 0.9981 - val_loss: 0.7546 - val_acc: 0.9333\n",
      "Epoch 18/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0119 - acc: 0.9975 - val_loss: 0.7390 - val_acc: 0.9314\n",
      "Epoch 19/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0112 - acc: 0.9968 - val_loss: 0.7283 - val_acc: 0.9314\n",
      "Epoch 20/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0104 - acc: 0.9981 - val_loss: 0.7127 - val_acc: 0.9295\n",
      "Epoch 21/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0099 - acc: 0.9981 - val_loss: 0.7020 - val_acc: 0.9333\n",
      "Epoch 22/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0094 - acc: 0.9981 - val_loss: 0.6909 - val_acc: 0.9295\n",
      "Epoch 23/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0088 - acc: 0.9981 - val_loss: 0.6835 - val_acc: 0.9295\n",
      "Epoch 24/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0083 - acc: 0.9981 - val_loss: 0.6732 - val_acc: 0.9276\n",
      "Epoch 25/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0080 - acc: 0.9981 - val_loss: 0.6628 - val_acc: 0.9238\n",
      "Epoch 26/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0076 - acc: 0.9981 - val_loss: 0.6519 - val_acc: 0.9238\n",
      "Epoch 27/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0073 - acc: 0.9981 - val_loss: 0.6412 - val_acc: 0.9257\n",
      "Epoch 28/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0070 - acc: 0.9981 - val_loss: 0.6342 - val_acc: 0.9238\n",
      "Epoch 29/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0068 - acc: 0.9981 - val_loss: 0.6254 - val_acc: 0.9276\n",
      "Epoch 30/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.6172 - val_acc: 0.9257\n",
      "Epoch 31/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0063 - acc: 0.9981 - val_loss: 0.6101 - val_acc: 0.9276\n",
      "Epoch 32/100\n",
      "1575/1575 [==============================] - 20s 12ms/step - loss: 0.0062 - acc: 0.9981 - val_loss: 0.6014 - val_acc: 0.9276\n",
      "Epoch 33/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0059 - acc: 0.9981 - val_loss: 0.5924 - val_acc: 0.9314\n",
      "Epoch 34/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0058 - acc: 0.9981 - val_loss: 0.5865 - val_acc: 0.9295\n",
      "Epoch 35/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0057 - acc: 0.9981 - val_loss: 0.5795 - val_acc: 0.9276\n",
      "Epoch 36/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0056 - acc: 0.9981 - val_loss: 0.5723 - val_acc: 0.9333\n",
      "Epoch 37/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0055 - acc: 0.9981 - val_loss: 0.5654 - val_acc: 0.9295\n",
      "Epoch 38/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0054 - acc: 0.9981 - val_loss: 0.5581 - val_acc: 0.9333\n",
      "Epoch 39/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0053 - acc: 0.9981 - val_loss: 0.5497 - val_acc: 0.9352\n",
      "Epoch 40/100\n",
      "1575/1575 [==============================] - 20s 13ms/step - loss: 0.0052 - acc: 0.9981 - val_loss: 0.5450 - val_acc: 0.9295\n",
      "Epoch 41/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0052 - acc: 0.9981 - val_loss: 0.5384 - val_acc: 0.9333\n",
      "Epoch 42/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0052 - acc: 0.9981 - val_loss: 0.5330 - val_acc: 0.9333\n",
      "Epoch 43/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0051 - acc: 0.9981 - val_loss: 0.5257 - val_acc: 0.9352\n",
      "Epoch 44/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0050 - acc: 0.9981 - val_loss: 0.5209 - val_acc: 0.9333\n",
      "Epoch 45/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0049 - acc: 0.9981 - val_loss: 0.5153 - val_acc: 0.9352\n",
      "Epoch 46/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0050 - acc: 0.9981 - val_loss: 0.5103 - val_acc: 0.9352\n",
      "Epoch 47/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0048 - acc: 0.9981 - val_loss: 0.5039 - val_acc: 0.9352\n",
      "Epoch 48/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0050 - acc: 0.9981 - val_loss: 0.4990 - val_acc: 0.9371\n",
      "Epoch 49/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0048 - acc: 0.9981 - val_loss: 0.4942 - val_acc: 0.9352\n",
      "Epoch 50/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0049 - acc: 0.9981 - val_loss: 0.4877 - val_acc: 0.9352\n",
      "Epoch 51/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0048 - acc: 0.9981 - val_loss: 0.4847 - val_acc: 0.9352\n",
      "Epoch 52/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0048 - acc: 0.9981 - val_loss: 0.4823 - val_acc: 0.9333\n",
      "Epoch 53/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0048 - acc: 0.9981 - val_loss: 0.4760 - val_acc: 0.9352\n",
      "Epoch 54/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0048 - acc: 0.9981 - val_loss: 0.4712 - val_acc: 0.9352\n",
      "Epoch 55/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0048 - acc: 0.9981 - val_loss: 0.4670 - val_acc: 0.9333\n",
      "Epoch 56/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0047 - acc: 0.9981 - val_loss: 0.4622 - val_acc: 0.9352\n",
      "Epoch 57/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0048 - acc: 0.9981 - val_loss: 0.4562 - val_acc: 0.9390\n",
      "Epoch 58/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0047 - acc: 0.9981 - val_loss: 0.4526 - val_acc: 0.9410\n",
      "Epoch 59/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0047 - acc: 0.9981 - val_loss: 0.4505 - val_acc: 0.9371\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0047 - acc: 0.9981 - val_loss: 0.4458 - val_acc: 0.9371\n",
      "Epoch 61/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0047 - acc: 0.9981 - val_loss: 0.4444 - val_acc: 0.9352\n",
      "Epoch 62/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0047 - acc: 0.9981 - val_loss: 0.4384 - val_acc: 0.9410\n",
      "Epoch 63/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0048 - acc: 0.9981 - val_loss: 0.4322 - val_acc: 0.9390\n",
      "Epoch 64/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0047 - acc: 0.9981 - val_loss: 0.4316 - val_acc: 0.9352\n",
      "Epoch 65/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0047 - acc: 0.9981 - val_loss: 0.4264 - val_acc: 0.9429\n",
      "Epoch 66/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0047 - acc: 0.9981 - val_loss: 0.4238 - val_acc: 0.9352\n",
      "Epoch 67/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0047 - acc: 0.9981 - val_loss: 0.4209 - val_acc: 0.9429\n",
      "Epoch 68/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0047 - acc: 0.9981 - val_loss: 0.4176 - val_acc: 0.9390\n",
      "Epoch 69/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0047 - acc: 0.9981 - val_loss: 0.4142 - val_acc: 0.9410\n",
      "Epoch 70/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 0.4120 - val_acc: 0.9410\n",
      "Epoch 71/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0047 - acc: 0.9981 - val_loss: 0.4077 - val_acc: 0.9410\n",
      "Epoch 72/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0047 - acc: 0.9981 - val_loss: 0.4058 - val_acc: 0.9429\n",
      "Epoch 73/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 0.4018 - val_acc: 0.9448\n",
      "Epoch 74/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 0.3980 - val_acc: 0.9467\n",
      "Epoch 75/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0047 - acc: 0.9981 - val_loss: 0.3960 - val_acc: 0.9429\n",
      "Epoch 76/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 0.3942 - val_acc: 0.9429\n",
      "Epoch 77/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 0.3903 - val_acc: 0.9486\n",
      "Epoch 78/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0045 - acc: 0.9981 - val_loss: 0.3906 - val_acc: 0.9410\n",
      "Epoch 79/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 0.3862 - val_acc: 0.9429\n",
      "Epoch 80/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 0.3854 - val_acc: 0.9410\n",
      "Epoch 81/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 0.3787 - val_acc: 0.9467\n",
      "Epoch 82/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 0.3754 - val_acc: 0.9505\n",
      "Epoch 83/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 0.3737 - val_acc: 0.9486\n",
      "Epoch 84/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 0.3729 - val_acc: 0.9467\n",
      "Epoch 85/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 0.3704 - val_acc: 0.9448\n",
      "Epoch 86/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0045 - acc: 0.9981 - val_loss: 0.3679 - val_acc: 0.9448\n",
      "Epoch 87/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 0.3682 - val_acc: 0.9429\n",
      "Epoch 88/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 0.3650 - val_acc: 0.9429\n",
      "Epoch 89/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 0.3593 - val_acc: 0.9505\n",
      "Epoch 90/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0046 - acc: 0.9975 - val_loss: 0.3614 - val_acc: 0.9429\n",
      "Epoch 91/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 0.3588 - val_acc: 0.9429\n",
      "Epoch 92/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 0.3539 - val_acc: 0.9505\n",
      "Epoch 93/100\n",
      "1575/1575 [==============================] - 19s 12ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 0.3514 - val_acc: 0.9505\n",
      "Epoch 94/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 0.3511 - val_acc: 0.9486\n",
      "Epoch 95/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 0.3503 - val_acc: 0.9486\n",
      "Epoch 96/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 0.3466 - val_acc: 0.9505\n",
      "Epoch 97/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 0.3441 - val_acc: 0.9448\n",
      "Epoch 98/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 0.3422 - val_acc: 0.9486\n",
      "Epoch 99/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0045 - acc: 0.9981 - val_loss: 0.3395 - val_acc: 0.9505\n",
      "Epoch 100/100\n",
      "1575/1575 [==============================] - 18s 12ms/step - loss: 0.0045 - acc: 0.9981 - val_loss: 0.3389 - val_acc: 0.9448\n"
     ]
    }
   ],
   "source": [
    "#Fitting the data:\n",
    "history = model.fit(X_train, y_train,\n",
    "                     epochs=100,\n",
    "                     verbose=True,\n",
    "                     validation_data=(X_test, y_test),\n",
    "                    batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575/1575 [==============================] - 2s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.004241822601682124, 0.9980952380952381]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525/525 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3388830413704827, 0.9447619047619048]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(model,open('Pickled models/gutenberg_tfidf_one_hidden','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_activity_regularizer',\n",
       " '_add_inbound_node',\n",
       " '_add_unique_metric_name',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_assert_input_compatibility',\n",
       " '_base_init',\n",
       " '_build_input_shape',\n",
       " '_cache_output_metric_attributes',\n",
       " '_call_and_compute_mask',\n",
       " '_call_convention',\n",
       " '_check_trainable_weights_consistency',\n",
       " '_checkpoint_dependencies',\n",
       " '_checkpointable_saver',\n",
       " '_collected_trainable_weights',\n",
       " '_compute_output_and_mask_jointly',\n",
       " '_compute_previous_mask',\n",
       " '_dataset_iterator_cache',\n",
       " '_deferred_dependencies',\n",
       " '_determine_call_convention',\n",
       " '_distribution_standardize_user_data',\n",
       " '_distribution_strategy',\n",
       " '_dtype',\n",
       " '_eager_set_inputs',\n",
       " '_expects_training_arg',\n",
       " '_extra_variables',\n",
       " '_feed_input_names',\n",
       " '_feed_input_shapes',\n",
       " '_feed_inputs',\n",
       " '_feed_loss_fns',\n",
       " '_feed_output_names',\n",
       " '_feed_output_shapes',\n",
       " '_feed_outputs',\n",
       " '_feed_sample_weight_modes',\n",
       " '_feed_sample_weights',\n",
       " '_feed_targets',\n",
       " '_function_kwargs',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_get_callback_model',\n",
       " '_get_iterator_get_next_tensors',\n",
       " '_get_node_attribute_at_index',\n",
       " '_graph',\n",
       " '_grouped_model',\n",
       " '_handle_activity_regularization',\n",
       " '_handle_deferred_dependencies',\n",
       " '_handle_metrics',\n",
       " '_handle_per_output_metrics',\n",
       " '_handle_weight_regularization',\n",
       " '_inbound_nodes',\n",
       " '_init_graph_network',\n",
       " '_init_metric_attributes',\n",
       " '_init_set_name',\n",
       " '_init_subclassed_network',\n",
       " '_input_coordinates',\n",
       " '_input_layers',\n",
       " '_inputs_from_call_args',\n",
       " '_is_compiled',\n",
       " '_is_graph_network',\n",
       " '_iterator_get_next',\n",
       " '_layers',\n",
       " '_layers_by_depth',\n",
       " '_lookup_dependency',\n",
       " '_losses',\n",
       " '_make_callback_model',\n",
       " '_make_predict_function',\n",
       " '_make_test_function',\n",
       " '_make_train_function',\n",
       " '_maybe_initialize_checkpointable',\n",
       " '_name',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_name_scope',\n",
       " '_network_nodes',\n",
       " '_no_dependency',\n",
       " '_nodes_by_depth',\n",
       " '_outbound_nodes',\n",
       " '_output_coordinates',\n",
       " '_output_layers',\n",
       " '_output_mask_cache',\n",
       " '_output_shape_cache',\n",
       " '_output_tensor_cache',\n",
       " '_per_output_metrics',\n",
       " '_per_output_weighted_metrics',\n",
       " '_preload_simple_restoration',\n",
       " '_restore_from_checkpoint_position',\n",
       " '_reuse',\n",
       " '_run_internal_graph',\n",
       " '_scope',\n",
       " '_set_connectivity_metadata_',\n",
       " '_set_inputs',\n",
       " '_set_learning_phase_metadata',\n",
       " '_set_mask_metadata',\n",
       " '_set_metric_attributes',\n",
       " '_set_per_output_metric_attributes',\n",
       " '_set_sample_weight_attributes',\n",
       " '_setattr_tracking',\n",
       " '_single_restoration_from_checkpoint_position',\n",
       " '_standardize_user_data',\n",
       " '_standardize_weights',\n",
       " '_symbolic_set_inputs',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " '_track_checkpointable',\n",
       " '_track_layers',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_deferred_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_unfiltered_losses',\n",
       " '_unfiltered_updates',\n",
       " '_update_uid',\n",
       " '_updated_config',\n",
       " '_updates',\n",
       " 'activity_regularizer',\n",
       " 'add',\n",
       " 'add_loss',\n",
       " 'add_update',\n",
       " 'add_variable',\n",
       " 'add_weight',\n",
       " 'apply',\n",
       " 'build',\n",
       " 'built',\n",
       " 'call',\n",
       " 'compile',\n",
       " 'compute_mask',\n",
       " 'compute_output_shape',\n",
       " 'count_params',\n",
       " 'dtype',\n",
       " 'evaluate',\n",
       " 'evaluate_generator',\n",
       " 'fit',\n",
       " 'fit_generator',\n",
       " 'from_config',\n",
       " 'get_config',\n",
       " 'get_input_at',\n",
       " 'get_input_mask_at',\n",
       " 'get_input_shape_at',\n",
       " 'get_layer',\n",
       " 'get_losses_for',\n",
       " 'get_output_at',\n",
       " 'get_output_mask_at',\n",
       " 'get_output_shape_at',\n",
       " 'get_updates_for',\n",
       " 'get_weights',\n",
       " 'history',\n",
       " 'inbound_nodes',\n",
       " 'input',\n",
       " 'input_mask',\n",
       " 'input_names',\n",
       " 'input_shape',\n",
       " 'input_spec',\n",
       " 'inputs',\n",
       " 'layers',\n",
       " 'load_weights',\n",
       " 'loss',\n",
       " 'loss_functions',\n",
       " 'loss_weights',\n",
       " 'loss_weights_list',\n",
       " 'losses',\n",
       " 'metrics',\n",
       " 'metrics_names',\n",
       " 'metrics_tensors',\n",
       " 'metrics_updates',\n",
       " 'name',\n",
       " 'non_trainable_variables',\n",
       " 'non_trainable_weights',\n",
       " 'optimizer',\n",
       " 'outbound_nodes',\n",
       " 'output',\n",
       " 'output_mask',\n",
       " 'output_names',\n",
       " 'output_shape',\n",
       " 'outputs',\n",
       " 'pop',\n",
       " 'predict',\n",
       " 'predict_classes',\n",
       " 'predict_function',\n",
       " 'predict_generator',\n",
       " 'predict_on_batch',\n",
       " 'predict_proba',\n",
       " 'reset_states',\n",
       " 'sample_weight_mode',\n",
       " 'sample_weight_modes',\n",
       " 'sample_weights',\n",
       " 'save',\n",
       " 'save_weights',\n",
       " 'set_weights',\n",
       " 'state_updates',\n",
       " 'stateful',\n",
       " 'stateful_metric_functions',\n",
       " 'stateful_metric_names',\n",
       " 'stop_training',\n",
       " 'summary',\n",
       " 'supports_masking',\n",
       " 'target_tensors',\n",
       " 'targets',\n",
       " 'test_function',\n",
       " 'test_on_batch',\n",
       " 'to_json',\n",
       " 'to_yaml',\n",
       " 'total_loss',\n",
       " 'train_function',\n",
       " 'train_on_batch',\n",
       " 'trainable',\n",
       " 'trainable_variables',\n",
       " 'trainable_weights',\n",
       " 'updates',\n",
       " 'uses_learning_phase',\n",
       " 'variables',\n",
       " 'weighted_metrics',\n",
       " 'weights']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<525x91374 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 230767 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer2 = TfidfVectorizer()\n",
    "X2 = vectorizer2.fit_transform(corpus.split('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<102195x91374 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1360640 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' With mind thus full happiness, Catherine hardly aware two three days passed away, without seeing Isabella minutes together. She began first sensible this, sigh conversation, walked along pump-room one morning, Mrs. Allens side, without anything say hear; scarcely felt five minutes longing friendship, object appeared, inviting secret conference, led way seat. “This favourite place,” said sat bench doors, commanded tolerable view everybody entering either; “it way.” Catherine, observing Isabellas eyes continually bent towards one door other, eager expectation, remembering often she falsely accused arch, thought present fine opportunity really so; therefore gaily said, “Do uneasy, Isabella, James soon here.” “Psha! My dear creature,” she replied, “do think such simpleton always wanting confine elbow. It would hideous always together; jest place. And going Northanger! I amazingly glad it. It one finest old places England, I understand. I shall depend upon particular description it.” “You '"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method fit_transform in module sklearn.preprocessing.label:\n",
      "\n",
      "fit_transform(y) method of sklearn.preprocessing.label.LabelBinarizer instance\n",
      "    Fit label binarizer and transform multi-class labels to binary\n",
      "    labels.\n",
      "    \n",
      "    The output of transform is sometimes referred to    as\n",
      "    the 1-of-K coding scheme.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y : array or sparse matrix of shape [n_samples,] or             [n_samples, n_classes]\n",
      "        Target values. The 2-d matrix should only contain 0 and 1,\n",
      "        represents multilabel classification. Sparse matrix can be\n",
      "        CSR, CSC, COO, DOK, or LIL.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    Y : array or CSR matrix of shape [n_samples, n_classes]\n",
      "        Shape will be [n_samples, 1] for binary problems.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(encoder.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
